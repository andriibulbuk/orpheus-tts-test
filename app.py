import streamlit as st
import os
import json
import glob
import re

def load_json(filepath):
    try:
        with open(filepath, "r") as f:
            return json.load(f)
    except Exception as e:
        st.error(f"Error loading JSON file {filepath}: {e}")
        return None

def display_sample(json_path, wav_path):
    sample_data = load_json(json_path)
    if sample_data:
        st.json(sample_data)
    else:
        st.error("Could not load JSON data.")
    if os.path.exists(wav_path):
        with open(wav_path, "rb") as f:
            st.audio(f.read(), format="audio/wav")
    else:
        st.error(f"WAV file not found: {wav_path}")

def group_by_attempt(json_files, pattern):
    """
    Groups json_files by attempt number.
    The regex pattern should capture the attempt number as group 2.
    Optionally group can capture additional info (e.g., voice, sentence index).
    Returns a dict {attempt_number: [filepath, ...]}.
    """
    groups = {}
    regex = re.compile(pattern)
    for filepath in json_files:
        filename = os.path.basename(filepath)
        match = regex.match(filename)
        if match:
            # Group 1: voice, Group 2: attempt, Group 3 (optional): sentence index
            attempt = match.group(2)
            groups.setdefault(attempt, []).append(filepath)
    return groups

def display_grouped_samples(folder, title, regex_pattern, sort_key_func=None):
    st.header(title)
    json_files = sorted(glob.glob(os.path.join(folder, "*.json")))
    if not json_files:
        st.info(f"No JSON files found in the '{folder}' folder.")
        return

    groups = group_by_attempt(json_files, regex_pattern)
    # Sort groups by attempt number (as integer)
    for attempt in sorted(groups.keys(), key=lambda x: int(x)):
        st.subheader(f"Attempt {attempt}")
        group_files = groups[attempt]
        # If a sort function is provided (e.g., for sentence files), use it.
        if sort_key_func:
            group_files = sorted(group_files, key=sort_key_func)
        # Use the first file's JSON to get description text.
        first_json = load_json(group_files[0])
        if first_json and "input_text" in first_json:
            st.markdown(f"**Prompt:** {first_json['input_text']}")
        else:
            st.markdown("**Prompt:** (no description available)")
        # For each file, display voice name, JSON, and audio.
        for json_file in group_files:
            filename = os.path.basename(json_file)
            # Extract voice name from filename (assumes format: voice-attempt-X... .json)
            voice_match = re.match(r"^(.*?)-attempt-", filename)
            voice = voice_match.group(1) if voice_match else "unknown"
            # Build corresponding wav path.
            wav_file = os.path.join(folder, os.path.splitext(filename)[0] + ".wav")
            st.markdown(f"**Voice:** {voice}")
            display_sample(json_file, wav_file)
            st.markdown("---")
        st.markdown("###")

st.title("TTS Testing Results")
st.write("All tests use 16-bit, 24 kHz audio as it is the default for the `canopylabs/orpheus-tts-0.1-finetune-prod` model and it can't be changed for now.")

# ----------------------------------------------------------------
# Section 1: Samples (grouped by attempt)
# Filenames like: tara-attempt-1.json, zac-attempt-1.json, zoe-attempt-1.json, etc.
# Regex: ^(.*?)-attempt-(\d+)\.json$
# ----------------------------------------------------------------
display_grouped_samples("samples", "Samples", r"^(.*?)-attempt-(\d+)\.json$")

# ----------------------------------------------------------------
# Section 2: Samples with GPU Utilization (grouped by attempt)
# Filenames like: julia-attempt-1.json, tara-attempt-1.json, zac-attempt-1.json, etc.
# ----------------------------------------------------------------
display_grouped_samples(
    "gpu-samples",
    "Samples with GPU Utilization Stats (Additional JSON details include A6000 GPU usage with 48.3 GB RAM)",
    r"^(.*?)-attempt-(\d+)\.json$"
)

# -------------------------
# Section 3: TTS Per Sentence (grouped by attempt)
# These sentences are sent individually from the LLM, which is important for capturing detailed timing
# and quality metrics for each sentence.
st.header("TTS Per Sentence")
st.markdown("**Note:** The sentences below are generated by sending individual sentences one-by-one. This approach is important because it allows us to capture detailed timing, latency, and quality metrics for each sentence separately.")
def sentence_sort_key(filepath):
    filename = os.path.basename(filepath)
    match = re.match(r"^(.*?)-attempt-(\d+)-sentence-(\d+)\.json$", filename)
    return int(match.group(3)) if match else 0

display_grouped_samples("samples-sentence", "TTS Per Sentence", r"^(.*?)-attempt-(\d+)-sentence-(\d+)\.json$", sort_key_func=sentence_sort_key)


# Finally, display the general merged WAV file if it exists.
merged_wav = os.path.join("samples-sentence", "output.wav")
st.markdown("General WAV File Merged using `ffmpeg -filter_complex` command")
if os.path.exists(merged_wav):
    with open(merged_wav, "rb") as f:
        st.audio(f.read(), format="audio/wav")
else:
    st.info("Merged WAV file 'output.wav' not found in the 'samples-sentence' folder.")

# -------------------------
# Conclusion
# -------------------------
st.header("Conclusion")
st.markdown(
    """
    Based on the tests, this model can be used as a TTS provider. However, it's important to note that a single TTS request to this model uses almost all available GPU memory. In practical terms, one NVIDIA A6000 GPU (with 48.3 GB of RAM) can handle only one request at a time. This makes the solution very resource-intensive and expensive.

    Additionally, the model currently supports only 24 kHz, 16-bit audio. This limitation should be considered when planning for development.
    """
)